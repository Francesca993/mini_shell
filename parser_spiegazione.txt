🧠 PARTE DI PARSING 
Parsing progettato in due fasi principali:

🔹 1. Lexer

Scopo: suddividere la stringa in token e associare ciascuno a un tipo (t_token_type).
Token riconosciuti:
WORD, PIPE, REDIR_IN (<), REDIR_OUT (>), APPEND (>>), HEREDOC (<<)
Gestione di:
Quote singole '...' e doppie "..." (senza espansione variabili al momento).
Controllo quote non chiuse (stampa errore e ritorna -1).
Funzioni chiave:
count_token() – calcola il numero totale di token.
fill_tokens() – popola gli array tokens e types.
handle_redirection() e handle_word() – gestiscono metacaratteri e parole/argomenti.
print_tokens() – debug visuale di token e tipi.

🔹 2. Parser

La funzione parse_line() chiama il lexer e stampa i token generati.
Attualmente non costruisce ancora strutture t_cmd (AST o pipeline), ma è predisposto per farlo.

📦 Struttura definita per il parser (parser.h)
t_cmd rappresenta un singolo comando:
typedef struct s_cmd {
    char    **args;
    char    *infile;
    char    *outfile;
    int     append;
    int     heredoc;
} t_cmd;
Il parser dovrebbe in futuro restituire un array di t_cmd* separati da pipe (|).

🔹 Output della lexer
int lexer(char *line, char ***tokens_out, t_token_type **types_out);
tokens_out → char **
Un array di stringhe, ogni stringa è un token (es: "grep", "<<", "ciao"…).
types_out → t_token_type *
Un array parallelo di enum, dove ogni elemento descrive il tipo del token corrispondente (WORD, PIPE, REDIR_IN, ...).

🧩 Prossimi passi 
Implementare la costruzione della pipeline
Una funzione tipo build_pipeline(char **tokens, t_token_type *types) che:
Suddivide i token tra pipe.
Associa correttamente input/output/append/heredoc a ciascun comando.
Costruisce array di t_cmd.
Gestione delle redirezioni
Interpretare correttamente <, >, >>, << assegnando i file a infile, outfile, append, heredoc.
Esecuzione comandi
Implementare execute_cmd(t_cmd **commands, char **env) con fork, execve, e gestione pipe.
Perfetto, allora conserviamo l'attuale output della lexer (i due array paralleli) e vediamo come passarli all’executor. Serve una fase intermedia: il parser, che costruisce delle strutture t_cmd più comode da usare in fase di esecuzione.

🔁 Flusso attuale:

readline() → lexer() → [tokens, types] → parser() → t_cmd** → executor()

🧱 Obiettivo del parser

Prendere:

char **tokens;         // ["grep", "ciao", "<", "input.txt", "|", "wc", "-l"]
t_token_type *types;   // [ WORD, WORD, REDIR_IN, WORD, PIPE, WORD, WORD ]
E costruire:

t_cmd **pipeline;      // array di comandi, separati da pipe
Ogni t_cmd rappresenta un singolo comando con i suoi argomenti e redirezioni:

typedef struct s_cmd {
    char    **args;      // ["grep", "ciao", NULL]
    char    *infile;     // "input.txt"
    char    *outfile;    // NULL o filename
    int     append;      // 1 se >>
    int     heredoc;     // 1 se <<
} t_cmd;
✅ Quindi per passare all'executor:

1. Costruisci t_cmd **pipeline nel parser
t_cmd **pipeline = build_pipeline(tokens, types);
2. Executor riceve la pipeline
void executor(t_cmd **pipeline, char **env);
Ogni t_cmd contiene:

gli argomenti da passare a execve()
gli eventuali file di redirezione da gestire prima del fork+exec
l’ordine (se è primo/ultimo/middle in una pipe)